"use strict";(self.webpackChunknlp_docs=self.webpackChunknlp_docs||[]).push([[9353],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>u});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=o.createContext({}),c=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=c(e.components);return o.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=c(n),u=r,f=m["".concat(s,".").concat(u)]||m[u]||d[u]||a;return n?o.createElement(f,i(i({ref:t},p),{},{components:n})):o.createElement(f,i({ref:t},p))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var c=2;c<a;c++)i[c]=n[c];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}m.displayName="MDXCreateElement"},5710:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var o=n(7462),r=(n(7294),n(3905));const a={},i="Microsoft Bot Framwork",l={unversionedId:"microsoft-bot-framework",id:"version-v3/microsoft-bot-framework",title:"Microsoft Bot Framwork",description:"Introduction",source:"@site/versioned_docs/version-v3/microsoft-bot-framework.md",sourceDirName:".",slug:"/microsoft-bot-framework",permalink:"/v3/microsoft-bot-framework",draft:!1,tags:[],version:"v3",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Logistic Regression NLU",permalink:"/v3/logistic-regression-nlu"},next:{title:"NER Manager",permalink:"/v3/ner-manager"}},s={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Example of use",id:"example-of-use",level:2},{value:"Recognizer and Slot filling",id:"recognizer-and-slot-filling",level:2}],p={toc:c};function d(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,o.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"microsoft-bot-framwork"},"Microsoft Bot Framwork"),(0,r.kt)("h2",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,"You can integrate it with Microsoft Bot Framework chatbots by importing the ",(0,r.kt)("em",{parentName:"p"},"Recognizer")," class from ",(0,r.kt)("em",{parentName:"p"},"node-nlp")," and using it as always. This will be enough to work as the LUIS Recognizer, using ",(0,r.kt)("inlineCode",{parentName:"p"},"bot.recognizer(recognizer);")," but as LUIS does not have NLG you'll have to develop how to integrate the answers and not only the intents."),(0,r.kt)("p",null,"If you want that the chatbot is automatically using the NLG, instead of calling ",(0,r.kt)("inlineCode",{parentName:"p"},"bot.recognizer(recognizer);")," that tells Microsoft Bot Framework to use the recognizer, use ",(0,r.kt)("inlineCode",{parentName:"p"},"recognizer.setBot(bot, true, 0.7);")," that is telling the recognizer what bot must be used, the second parameter (optional) is true to override the usual behaviour of Microsoft Bot Framework with the improved behaviour of the recognizer, and the last parameter (optional) is the threshold that indicates that the intent response must be used instead of triggering the next step of the dialogs."),(0,r.kt)("p",null,"Another feature that comes with the improved behaviour, is that when the answer starts with ",(0,r.kt)("em",{parentName:"p"},"/")," then is not a phrase to return to the user, and is a ",(0,r.kt)("em",{parentName:"p"},"session.beginDialog()"),", so the dialog of the given name is raised and pushed into the dialog stack."),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"https://github.com/axa-group/nlp.js/blob/master/screenshots/slotfilling.gif",alt:"Example"})),(0,r.kt)("h2",{id:"example-of-use"},"Example of use"),(0,r.kt)("p",null,"Example of a bot using Microsoft Bot Framework and NLP.js.\nTo create the bot create a folder and start a new node project with npm init. Then install the dependencies:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"npm i botbuilder express node-nlp\n")),(0,r.kt)("p",null,"Put the code in the index.js, and in the same folder put an excel file with the NLP information.\nExecute it and the magic will happen. The bot will be trained the first time you start the app, so first time will take some time to train, but next times will load the already trained model."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},"const builder = require('botbuilder');\nconst express = require('express');\nconst fs = require('fs');\nconst { Recognizer } = require('node-nlp');\n\nconst modelName = './model.nlp';\nconst excelName = './model.xls';\n\n// Creates a connector for the chatbot\nconst connector = new builder.ChatConnector({\n  appId: process.env.BOT_APP_ID,\n  appPassword: process.env.BOT_APP_PASSWORD,\n});\n\n// Creates a node-nlp recognizer for the bot\nconst recognizer = new Recognizer();\nif (fs.existsSync(modelName)) {\n  recognizer.load(modelName);\n} else {\n  recognizer.loadExcel(excelName);\n  recognizer.save(modelName);\n}\n\n// Creates the bot using a memory storage, with a main dialog that\n// use the node-nlp recognizer to calculate the answer.\nconst bot = new builder.UniversalBot(connector, session => {\n  session.send(\n    `You reached the default message handler. You said '${\n      session.message.text\n    }'.`,\n  );\n}).set('storage', new builder.MemoryBotStorage());\n\nrecognizer.setBot(bot, true);\n\n// Creates the express application\nconst app = express();\nconst port = process.env.PORT || 3000;\napp.post('/api/messages', connector.listen());\napp.listen(port);\nconsole.log(`Chatbot listening on port ${port}`);\n")),(0,r.kt)("h2",{id:"recognizer-and-slot-filling"},"Recognizer and Slot filling"),(0,r.kt)("p",null,"Slot filling is done automatically when using the recognizer for microsoft bot framework when the behaviour overrided to be the one of NLP.js."),(0,r.kt)("p",null,"Example code for slot filling:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},"const recognizer = new Recognizer();\nrecognizer.nlpManager.addLanguage('en');\nconst fromEntity = recognizer.nlpManager.addTrimEntity('fromCity');\nfromEntity.addBetweenCondition('en', 'from', 'to', { skip: ['travel'] });\nfromEntity.addAfterLastCondition('en', 'from', { skip: ['travel'] });\nconst toEntity = recognizer.nlpManager.addTrimEntity('toCity');\ntoEntity.addBetweenCondition('en', 'to', 'from', { skip: ['travel'] });\ntoEntity.addAfterLastCondition('en', 'to', { skip: ['travel'] });\nrecognizer.nlpManager.slotManager.addSlot('travel', 'toCity', true, {\n  en: 'Where do you want to go?',\n});\nrecognizer.nlpManager.slotManager.addSlot('travel', 'fromCity', true, {\n  en: 'From where you are traveling?',\n});\nrecognizer.nlpManager.slotManager.addSlot('travel', 'date', true, {\n  en: 'When do you want to travel?',\n});\nrecognizer.nlpManager.addDocument(\n  'en',\n  'I want to travel from %fromCity% to %toCity% %date%',\n  'travel',\n);\nrecognizer.nlpManager.addAnswer(\n  'en',\n  'travel',\n  'You want to travel from {{ fromCity }} to {{ toCity }} {{ date }}',\n);\nawait recognizer.nlpManager.train();\n")),(0,r.kt)("p",null,"With this example what we achieve is that the user can use the intent providing partial information, and the bot automatically ask the information not provided. So we can have conversations like:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"user> I want to travel\nbot> Where do you want to go?\nuser> London\nbot> From where you are traveling?\nuser> Barcelona\nbot> When do you want to travel?\nuser> tomorrow\nbot> You want to travel from Barcelona to London tomorrow\n")),(0,r.kt)("p",null,"But also can provide some information or all at the first utterance of the intent:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"user> I want to travel tomorrow to London\nbot> From where you are traveling?\nuser> Barcelona\nbot> You want to travel from Barcelona to London tomorrow\n")),(0,r.kt)("p",null,"You have an example of a Microsoft Bot Framework bot with an intent with slot filling at ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/axa-group/nlp.js/tree/master/examples/microsoft-bot"},(0,r.kt)("inlineCode",{parentName:"a"},"/examples/microsoft-bot"))))}d.isMDXComponent=!0}}]);
"use strict";(self.webpackChunknlp_docs=self.webpackChunknlp_docs||[]).push([[8559],{3905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>d});var o=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,o,r=function(e,n){if(null==e)return{};var t,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var i=o.createContext({}),p=function(e){var n=o.useContext(i),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},m=function(e){var n=p(e.components);return o.createElement(i.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},c=o.forwardRef((function(e,n){var t=e.components,r=e.mdxType,a=e.originalType,i=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),c=p(t),d=r,g=c["".concat(i,".").concat(d)]||c[d]||u[d]||a;return t?o.createElement(g,s(s({ref:n},m),{},{components:t})):o.createElement(g,s({ref:n},m))}));function d(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=t.length,s=new Array(a);s[0]=c;var l={};for(var i in n)hasOwnProperty.call(n,i)&&(l[i]=n[i]);l.originalType=e,l.mdxType="string"==typeof e?e:r,s[1]=l;for(var p=2;p<a;p++)s[p]=t[p];return o.createElement.apply(null,s)}return o.createElement.apply(null,t)}c.displayName="MDXCreateElement"},8032:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>l,toc:()=>p});var o=t(7462),r=(t(7294),t(3905));const a={title:"@nlpjs/lang-en"},s="@nlpjs/lang-en",l={unversionedId:"language_support/modules/lang-en",id:"language_support/modules/lang-en",title:"@nlpjs/lang-en",description:"Installation",source:"@site/docs/03-language_support/02-modules/lang-en.md",sourceDirName:"03-language_support/02-modules",slug:"/language_support/modules/lang-en",permalink:"/language_support/modules/lang-en",draft:!1,tags:[],version:"current",frontMatter:{title:"@nlpjs/lang-en"},sidebar:"tutorialSidebar",previous:{title:"@nlpjs/lang-en-min",permalink:"/language_support/modules/land-en-min"},next:{title:"@nlpjs/lang-es",permalink:"/language_support/modules/lang-es"}},i={},p=[{value:"Installation",id:"installation",level:2},{value:"Normalization",id:"normalization",level:2},{value:"Tokenization",id:"tokenization",level:2},{value:"Identify if a word is an english stopword",id:"identify-if-a-word-is-an-english-stopword",level:2},{value:"Remove stopwords from an array of words",id:"remove-stopwords-from-an-array-of-words",level:2},{value:"Change the stopwords dictionary",id:"change-the-stopwords-dictionary",level:2},{value:"Stemming word by word",id:"stemming-word-by-word",level:2},{value:"Stemming an array of words",id:"stemming-an-array-of-words",level:2},{value:"Normalizing, Tokenizing and Stemming a sentence",id:"normalizing-tokenizing-and-stemming-a-sentence",level:2},{value:"Remove stopwords when stemming a sentence",id:"remove-stopwords-when-stemming-a-sentence",level:2},{value:"Sentiment Analysis",id:"sentiment-analysis",level:2},{value:"Example of usage on a classifier",id:"example-of-usage-on-a-classifier",level:2}],m={toc:p};function u(e){let{components:n,...t}=e;return(0,r.kt)("wrapper",(0,o.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"nlpjslang-en"},"@nlpjs/lang-en"),(0,r.kt)("h2",{id:"installation"},"Installation"),(0,r.kt)("p",null,"You can install @nlpjs/lang-en:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"    npm install @nlpjs/lang-en\n")),(0,r.kt)("h2",{id:"normalization"},"Normalization"),(0,r.kt)("p",null,"Normalization of a text converts it to lowercase and remove decorations of characters."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { NormalizerEn } = require("@nlpjs/lang-en");\n\nconst normalizer = new NormalizerEn();\nconst input = "This sh\xf3uld be normalized";\nconst result = normalizer.normalize(input);\nconsole.log(result);\n// output: this should be normalized\n')),(0,r.kt)("h2",{id:"tokenization"},"Tokenization"),(0,r.kt)("p",null,"Tokenization splits a sentence into words."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},"const { TokenizerEn } = require(\"@nlpjs/lang-en\");\n\nconst tokenizer = new TokenizerEn();\nconst input = \"This isn't tokenized yet\";\nconst result = tokenizer.tokenize(input);\nconsole.log(result);\n// output: [ 'This', 'is', 'not', 'tokenized', 'yet' ]\n")),(0,r.kt)("p",null,"Tokenizer can also normalize the sentence before tokenizing, to do that provide a ",(0,r.kt)("em",{parentName:"p"},"true")," as second argument to the method ",(0,r.kt)("em",{parentName:"p"},"tokenize")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},"const { TokenizerEn } = require('@nlpjs/lang-en');\n\nconst tokenizer = new TokenizerEn();\nconst input = 'This isn\\'t tokenized yet';\nconst result = tokenizer.tokenize(input true);\nconsole.log(result);\n// output: [ 'this', 'is', 'not', 'tokenized', 'yet' ]\n")),(0,r.kt)("h2",{id:"identify-if-a-word-is-an-english-stopword"},"Identify if a word is an english stopword"),(0,r.kt)("p",null,"Using the class ",(0,r.kt)("em",{parentName:"p"},"StopwordsEn")," you can identify if a word is an stopword:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { StopwordsEn } = require("@nlpjs/lang-en");\n\nconst stopwords = new StopwordsEn();\nconsole.log(stopwords.isStopword("is"));\n// output: true\nconsole.log(stopwords.isStopword("developer"));\n// output: false\n')),(0,r.kt)("h2",{id:"remove-stopwords-from-an-array-of-words"},"Remove stopwords from an array of words"),(0,r.kt)("p",null,"Using the class ",(0,r.kt)("em",{parentName:"p"},"StopwordsEn")," you can remove stopwords form an array of words:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { StopwordsEn } = require("@nlpjs/lang-en");\n\nconst stopwords = new StopwordsEn();\nconsole.log(stopwords.removeStopwords(["who", "is", "your", "develop"]));\n// output: [\'develop\']\n')),(0,r.kt)("h2",{id:"change-the-stopwords-dictionary"},"Change the stopwords dictionary"),(0,r.kt)("p",null,"Using the class ",(0,r.kt)("em",{parentName:"p"},"StopwordsEn")," you can restart it dictionary and build it from another set of words:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { StopwordsEn } = require("@nlpjs/lang-en");\n\nconst stopwords = new StopwordsEn();\nstopwords.dictionary = {};\nstopwords.build(["is", "your"]);\nconsole.log(stopwords.removeStopwords(["who", "is", "your", "develop"]));\n// output: [\'who\', \'develop\']\n')),(0,r.kt)("h2",{id:"stemming-word-by-word"},"Stemming word by word"),(0,r.kt)("p",null,"An stemmer is an algorithm to calculate the ",(0,r.kt)("em",{parentName:"p"},"stem")," (root) of a word, removing affixes."),(0,r.kt)("p",null,"You can stem one word using method ",(0,r.kt)("em",{parentName:"p"},"stemWord"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { StemmerEn } = require("@nlpjs/lang-en");\n\nconst stemmer = new StemmerEn();\nconst input = "developer";\nconsole.log(stemmer.stemWord(input));\n// output: develop\n')),(0,r.kt)("h2",{id:"stemming-an-array-of-words"},"Stemming an array of words"),(0,r.kt)("p",null,"You can stem an array of words using method ",(0,r.kt)("em",{parentName:"p"},"stem"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { StemmerEn } = require("@nlpjs/lang-en");\n\nconst stemmer = new StemmerEn();\nconst input = ["Who", "is", "your", "developer"];\nconsole.log(stemmer.stem(input));\n// outuput: [ \'Who\', \'is\', \'your\', \'develop\' ]\n')),(0,r.kt)("h2",{id:"normalizing-tokenizing-and-stemming-a-sentence"},"Normalizing, Tokenizing and Stemming a sentence"),(0,r.kt)("p",null,"As you can see, stemmer does not do internal normalization, so words with uppercases will remain uppercased.\nAlso, stemmer works with lowercased affixes, so ",(0,r.kt)("em",{parentName:"p"},"developer")," will be stemmed as ",(0,r.kt)("em",{parentName:"p"},"develop")," but ",(0,r.kt)("em",{parentName:"p"},"DEVELOPER")," will not be changed."),(0,r.kt)("p",null,"You can tokenize and stem a sentence, including normalization, with the method ",(0,r.kt)("em",{parentName:"p"},"tokenizeAndStem"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},"const { StemmerEn } = require(\"@nlpjs/lang-en\");\n\nconst stemmer = new StemmerEn();\nconst input = \"Who is your DEVELOPER\";\nconsole.log(stemmer.tokenizeAndStem(input));\n// output: [ 'who', 'is', 'your', 'develop' ]\n")),(0,r.kt)("h2",{id:"remove-stopwords-when-stemming-a-sentence"},"Remove stopwords when stemming a sentence"),(0,r.kt)("p",null,"When calling ",(0,r.kt)("em",{parentName:"p"},"tokenizeAndStem")," method from the class ",(0,r.kt)("em",{parentName:"p"},"StemmerEn"),", the second parameter is a boolean to set if the stemmer must keep the stopwords (true) or remove them (false). Before using it, the stopwords instance must be set into the stemmer:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { StemmerEn, StopwordsEn } = require("@nlpjs/lang-en");\n\nconst stemmer = new StemmerEn();\nstemmer.stopwords = new StopwordsEn();\nconst input = "who is your developer";\nconsole.log(stemmer.tokenizeAndStem(input, false));\n// output: [\'develop\']\n')),(0,r.kt)("h2",{id:"sentiment-analysis"},"Sentiment Analysis"),(0,r.kt)("p",null,"To use sentiment analysis you'll need to create a new ",(0,r.kt)("em",{parentName:"p"},"Container")," and use the plugin ",(0,r.kt)("em",{parentName:"p"},"LangEn"),", because internally the ",(0,r.kt)("em",{parentName:"p"},"SentimentAnalyzer")," class try to retrieve the normalizer, tokenizer, stemmmer and sentiment dictionaries from the container."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { Container } = require("@nlpjs/core");\nconst { SentimentAnalyzer } = require("@nlpjs/sentiment");\nconst { LangEn } = require("@nlpjs/lang-en");\n\n(async () => {\n  const container = new Container();\n  container.use(LangEn);\n  const sentiment = new SentimentAnalyzer({ container });\n  const result = await sentiment.process({ locale: "en", text: "I love cats" });\n  console.log(result.sentiment);\n})();\n// output:\n// {\n//   score: 0.5,\n//   numWords: 3,\n//   numHits: 1,\n//   average: 0.16666666666666666,\n//   type: \'senticon\',\n//   locale: \'en\',\n//   vote: \'positive\'\n// }\n')),(0,r.kt)("p",null,"The output of the sentiment analysis includes:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"score"),": final score of the sentence."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"numWords"),": total words of the sentence."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"numHits"),": total words of the sentence identified as having a sentiment score."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"average"),": score divided by numWords"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"type"),": type of dictionary used, values can be afinn, senticon or pattern."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"locale"),": locale of the sentence"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"vote"),": positive if score greater than 0, negative if score lower than 0, neutral if score equals 0.")),(0,r.kt)("h2",{id:"example-of-usage-on-a-classifier"},"Example of usage on a classifier"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const { containerBootstrap } = require("@nlpjs/core");\nconst { Nlp } = require("@nlpjs/nlp");\nconst { LangEn } = require("@nlpjs/lang-en");\n\n(async () => {\n  const container = await containerBootstrap();\n  container.use(Nlp);\n  container.use(LangEn);\n  const nlp = container.get("nlp");\n  nlp.settings.autoSave = false;\n  nlp.addLanguage("en");\n  // Adds the utterances and intents for the NLP\n  nlp.addDocument("en", "goodbye for now", "greetings.bye");\n  nlp.addDocument("en", "bye bye take care", "greetings.bye");\n  nlp.addDocument("en", "okay see you later", "greetings.bye");\n  nlp.addDocument("en", "bye for now", "greetings.bye");\n  nlp.addDocument("en", "i must go", "greetings.bye");\n  nlp.addDocument("en", "hello", "greetings.hello");\n  nlp.addDocument("en", "hi", "greetings.hello");\n  nlp.addDocument("en", "howdy", "greetings.hello");\n\n  // Train also the NLG\n  nlp.addAnswer("en", "greetings.bye", "Till next time");\n  nlp.addAnswer("en", "greetings.bye", "see you soon!");\n  nlp.addAnswer("en", "greetings.hello", "Hey there!");\n  nlp.addAnswer("en", "greetings.hello", "Greetings!");\n  await nlp.train();\n  const response = await nlp.process("en", "I should go now");\n  console.log(response);\n})();\n')))}u.isMDXComponent=!0}}]);